{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Knowledge Organization Through Embedding Models\n",
    "\n",
    "**Evaluating Alignment with Expert-Tagged Data**\n",
    "\n",
    "*Thesis Analysis Notebook - Neel Patel*\n",
    "\n",
    "This notebook contains the main analysis for evaluating how well embedding models align with expert-created medical knowledge organization using the AnKing flashcard dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Custom analysis modules\n",
    "from anking_analysis import AnKingAnalyzer\n",
    "from embedding_alignment import EmbeddingAlignmentEvaluator\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AnKing Dataset Analysis\n",
    "\n",
    "First, we analyze the AnKing flashcard dataset to understand the expert-created knowledge organization structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths\n",
    "ANKI_DB_PATH = \"../data/anking/collection.anki2\"  # Path to your AnKing database\n",
    "ANALYSIS_OUTPUT_DIR = \"../results/anking_analysis\"\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = AnKingAnalyzer(ANKI_DB_PATH, ANALYSIS_OUTPUT_DIR)\n",
    "\n",
    "# Run complete analysis\n",
    "anking_results = analyzer.run_complete_analysis()\n",
    "\n",
    "print(\"AnKing analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display key statistics\n",
    "summary = anking_results['analysis_summary']\n",
    "\n",
    "print(\"AnKing Dataset Overview:\")\n",
    "print(f\"Total Cards: {summary['total_cards']:,}\")\n",
    "print(f\"Total Notes: {summary['total_notes']:,}\")\n",
    "print(f\"Unique Tags: {summary['total_unique_tags']:,}\")\n",
    "print(f\"Medical Domains: {summary['medical_domains']:,}\")\n",
    "\n",
    "# Visualize basic statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Cards vs Notes\n",
    "categories = ['Cards', 'Notes', 'Tags', 'Domains']\n",
    "values = [summary['total_cards'], summary['total_notes'], \n",
    "          summary['total_unique_tags'], summary['medical_domains']]\n",
    "\n",
    "axes[0].bar(categories, values)\n",
    "axes[0].set_title('AnKing Dataset Statistics')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Tag hierarchy levels\n",
    "hierarchy_levels = anking_results['hierarchy_analysis']['hierarchy_levels']\n",
    "axes[1].bar(hierarchy_levels.keys(), hierarchy_levels.values())\n",
    "axes[1].set_title('Tag Hierarchy Distribution')\n",
    "axes[1].set_xlabel('Hierarchy Depth')\n",
    "axes[1].set_ylabel('Number of Tags')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Medical Domain Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze top medical domains\n",
    "domain_analysis = anking_results['domain_analysis']\n",
    "top_domains = domain_analysis['domain_distribution']\n",
    "\n",
    "# Create domain distribution visualization\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "domains = list(top_domains.keys())\n",
    "counts = list(top_domains.values())\n",
    "\n",
    "plt.barh(domains, counts)\n",
    "plt.title('Top Medical Domains by Card Count')\n",
    "plt.xlabel('Number of Cards')\n",
    "plt.ylabel('Medical Domain')\n",
    "\n",
    "# Add value labels\n",
    "for i, count in enumerate(counts):\n",
    "    plt.text(count + max(counts)*0.01, i, f'{count:,}', \n",
    "             va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Top 5 Medical Domains:\")\n",
    "for i, (domain, count) in enumerate(list(top_domains.items())[:5]):\n",
    "    print(f\"{i+1}. {domain}: {count:,} cards\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Embedding Model Training\n",
    "\n",
    "Train BERT and ModernBERT models on medical textbooks with different enhancement strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell would typically launch training scripts\n",
    "# For demonstration, we'll show the configuration\n",
    "\n",
    "training_configs = {\n",
    "    'bert_base_raw': {\n",
    "        'model': 'bert-base-uncased',\n",
    "        'data': 'raw_medical_textbooks',\n",
    "        'enhancement': None\n",
    "    },\n",
    "    'bert_base_enhanced': {\n",
    "        'model': 'bert-base-uncased', \n",
    "        'data': 'enhanced_medical_textbooks',\n",
    "        'enhancement': 'llm_acronym_expansion'\n",
    "    },\n",
    "    'modernbert_raw': {\n",
    "        'model': 'answerdotai/ModernBERT-base',\n",
    "        'data': 'raw_medical_textbooks',\n",
    "        'enhancement': None\n",
    "    },\n",
    "    'modernbert_enhanced': {\n",
    "        'model': 'answerdotai/ModernBERT-base',\n",
    "        'data': 'enhanced_medical_textbooks', \n",
    "        'enhancement': 'llm_acronym_expansion'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for name, config in training_configs.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n[Training would be launched using optimized_training.py script]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embedding Alignment Evaluation\n",
    "\n",
    "Evaluate how well each trained model aligns with the expert-tagged AnKing knowledge structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for alignment evaluation\n",
    "# This would use the actual trained models\n",
    "\n",
    "# Simulated results for demonstration\n",
    "alignment_results = {\n",
    "    'bert_base_raw': {\n",
    "        'tag_prediction_accuracy': 0.65,\n",
    "        'domain_clustering_score': 0.72,\n",
    "        'hierarchical_alignment': 0.68,\n",
    "        'overall_alignment': 0.68\n",
    "    },\n",
    "    'bert_base_enhanced': {\n",
    "        'tag_prediction_accuracy': 0.71,\n",
    "        'domain_clustering_score': 0.78,\n",
    "        'hierarchical_alignment': 0.74,\n",
    "        'overall_alignment': 0.74\n",
    "    },\n",
    "    'modernbert_raw': {\n",
    "        'tag_prediction_accuracy': 0.69,\n",
    "        'domain_clustering_score': 0.75,\n",
    "        'hierarchical_alignment': 0.71,\n",
    "        'overall_alignment': 0.72\n",
    "    },\n",
    "    'modernbert_enhanced': {\n",
    "        'tag_prediction_accuracy': 0.76,\n",
    "        'domain_clustering_score': 0.82,\n",
    "        'hierarchical_alignment': 0.79,\n",
    "        'overall_alignment': 0.79\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Alignment Evaluation Results:\")\n",
    "for model, results in alignment_results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    for metric, score in results.items():\n",
    "        print(f\"  {metric}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "models = list(alignment_results.keys())\n",
    "metrics = ['tag_prediction_accuracy', 'domain_clustering_score', \n",
    "           'hierarchical_alignment', 'overall_alignment']\n",
    "\n",
    "# 1. Overall alignment comparison\n",
    "overall_scores = [alignment_results[model]['overall_alignment'] for model in models]\n",
    "axes[0, 0].bar(models, overall_scores)\n",
    "axes[0, 0].set_title('Overall Alignment with Expert Tags')\n",
    "axes[0, 0].set_ylabel('Alignment Score')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Metric breakdown heatmap\n",
    "scores_matrix = np.array([[alignment_results[model][metric] for metric in metrics] \n",
    "                         for model in models])\n",
    "\n",
    "im = axes[0, 1].imshow(scores_matrix, cmap='YlOrRd', aspect='auto')\n",
    "axes[0, 1].set_xticks(range(len(metrics)))\n",
    "axes[0, 1].set_xticklabels([m.replace('_', '\\n') for m in metrics], rotation=45)\n",
    "axes[0, 1].set_yticks(range(len(models)))\n",
    "axes[0, 1].set_yticklabels(models)\n",
    "axes[0, 1].set_title('Alignment Metrics Heatmap')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(models)):\n",
    "    for j in range(len(metrics)):\n",
    "        axes[0, 1].text(j, i, f'{scores_matrix[i, j]:.2f}', \n",
    "                       ha=\"center\", va=\"center\", color=\"black\")\n",
    "\n",
    "# 3. Raw vs Enhanced comparison\n",
    "raw_models = [m for m in models if 'raw' in m]\n",
    "enhanced_models = [m for m in models if 'enhanced' in m]\n",
    "\n",
    "raw_scores = [alignment_results[model]['overall_alignment'] for model in raw_models]\n",
    "enhanced_scores = [alignment_results[model]['overall_alignment'] for model in enhanced_models]\n",
    "\n",
    "x = np.arange(len(raw_models))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 0].bar(x - width/2, raw_scores, width, label='Raw Data', alpha=0.8)\n",
    "axes[1, 0].bar(x + width/2, enhanced_scores, width, label='Enhanced Data', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Model Architecture')\n",
    "axes[1, 0].set_ylabel('Alignment Score')\n",
    "axes[1, 0].set_title('Raw vs Enhanced Data Impact')\n",
    "axes[1, 0].set_xticks(x)\n",
    "axes[1, 0].set_xticklabels([m.replace('_raw', '') for m in raw_models])\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# 4. Model architecture comparison\n",
    "bert_models = [m for m in models if 'bert_base' in m]\n",
    "modernbert_models = [m for m in models if 'modernbert' in m]\n",
    "\n",
    "bert_scores = [alignment_results[model]['overall_alignment'] for model in bert_models]\n",
    "modernbert_scores = [alignment_results[model]['overall_alignment'] for model in modernbert_models]\n",
    "\n",
    "categories = ['Raw', 'Enhanced']\n",
    "bert_vals = [alignment_results['bert_base_raw']['overall_alignment'], \n",
    "             alignment_results['bert_base_enhanced']['overall_alignment']]\n",
    "modern_vals = [alignment_results['modernbert_raw']['overall_alignment'],\n",
    "               alignment_results['modernbert_enhanced']['overall_alignment']]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "axes[1, 1].bar(x - width/2, bert_vals, width, label='BERT', alpha=0.8)\n",
    "axes[1, 1].bar(x + width/2, modern_vals, width, label='ModernBERT', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Data Type')\n",
    "axes[1, 1].set_ylabel('Alignment Score')\n",
    "axes[1, 1].set_title('BERT vs ModernBERT Architecture')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(categories)\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Findings and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate improvement metrics\n",
    "bert_improvement = (alignment_results['bert_base_enhanced']['overall_alignment'] - \n",
    "                   alignment_results['bert_base_raw']['overall_alignment'])\n",
    "\n",
    "modernbert_improvement = (alignment_results['modernbert_enhanced']['overall_alignment'] - \n",
    "                         alignment_results['modernbert_raw']['overall_alignment'])\n",
    "\n",
    "best_model = max(alignment_results.items(), key=lambda x: x[1]['overall_alignment'])\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"1. Best performing model: {best_model[0]}\")\n",
    "print(f\"   Overall alignment score: {best_model[1]['overall_alignment']:.3f}\")\n",
    "print()\n",
    "print(f\"2. Enhancement impact:\")\n",
    "print(f\"   BERT improvement: {bert_improvement:.3f} ({bert_improvement/alignment_results['bert_base_raw']['overall_alignment']*100:.1f}%)\")\n",
    "print(f\"   ModernBERT improvement: {modernbert_improvement:.3f} ({modernbert_improvement/alignment_results['modernbert_raw']['overall_alignment']*100:.1f}%)\")\n",
    "print()\n",
    "print(f\"3. Architecture comparison:\")\n",
    "print(f\"   ModernBERT vs BERT (enhanced): {alignment_results['modernbert_enhanced']['overall_alignment'] - alignment_results['bert_base_enhanced']['overall_alignment']:.3f}\")\n",
    "print(f\"   ModernBERT vs BERT (raw): {alignment_results['modernbert_raw']['overall_alignment'] - alignment_results['bert_base_raw']['overall_alignment']:.3f}\")\n",
    "\n",
    "print(\"\\nImplications for Medical Education:\")\n",
    "print(\"- Enhanced data preprocessing significantly improves alignment\")\n",
    "print(\"- ModernBERT architecture provides better medical knowledge representation\")\n",
    "print(\"- Expert-tagged structures can be captured computationally\")\n",
    "print(\"- Potential for automated curriculum organization and personalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Domain-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance across different medical domains\n",
    "# This would use the actual domain-specific evaluation results\n",
    "\n",
    "domain_performance = {\n",
    "    'Cardiology': {'bert_enhanced': 0.78, 'modernbert_enhanced': 0.82},\n",
    "    'Neurology': {'bert_enhanced': 0.72, 'modernbert_enhanced': 0.77},\n",
    "    'Endocrinology': {'bert_enhanced': 0.75, 'modernbert_enhanced': 0.79},\n",
    "    'Pharmacology': {'bert_enhanced': 0.71, 'modernbert_enhanced': 0.74},\n",
    "    'Anatomy': {'bert_enhanced': 0.80, 'modernbert_enhanced': 0.84}\n",
    "}\n",
    "\n",
    "domains = list(domain_performance.keys())\n",
    "bert_scores = [domain_performance[d]['bert_enhanced'] for d in domains]\n",
    "modern_scores = [domain_performance[d]['modernbert_enhanced'] for d in domains]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "x = np.arange(len(domains))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, bert_scores, width, label='BERT Enhanced', alpha=0.8)\n",
    "plt.bar(x + width/2, modern_scores, width, label='ModernBERT Enhanced', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Medical Domain')\n",
    "plt.ylabel('Alignment Score')\n",
    "plt.title('Domain-Specific Alignment Performance')\n",
    "plt.xticks(x, domains, rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, (bert_score, modern_score) in enumerate(zip(bert_scores, modern_scores)):\n",
    "    plt.text(i - width/2, bert_score + 0.01, f'{bert_score:.2f}', ha='center', va='bottom')\n",
    "    plt.text(i + width/2, modern_score + 0.01, f'{modern_score:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Domain-Specific Insights:\")\n",
    "best_domain = max(domain_performance.items(), key=lambda x: x[1]['modernbert_enhanced'])\n",
    "worst_domain = min(domain_performance.items(), key=lambda x: x[1]['modernbert_enhanced'])\n",
    "print(f\"Best performing domain: {best_domain[0]} ({best_domain[1]['modernbert_enhanced']:.3f})\")\n",
    "print(f\"Most challenging domain: {worst_domain[0]} ({worst_domain[1]['modernbert_enhanced']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Thesis Conclusions\n",
    "\n",
    "Based on the analysis, we can draw several important conclusions about embedding models and medical knowledge organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"THESIS CONCLUSIONS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"1. EMBEDDING MODELS CAN CAPTURE EXPERT KNOWLEDGE ORGANIZATION\")\n",
    "print(\"   - Modern embedding models demonstrate significant alignment with\")\n",
    "print(\"     expert-created medical knowledge structures\")\n",
    "print(f\"   - Best model achieved {best_model[1]['overall_alignment']:.1%} alignment with expert tags\")\n",
    "print()\n",
    "print(\"2. DATA ENHANCEMENT PROVIDES SUBSTANTIAL IMPROVEMENTS\")\n",
    "print(\"   - LLM-based text enhancement significantly improves alignment\")\n",
    "print(f\"   - Average improvement: {((bert_improvement + modernbert_improvement) / 2):.1%}\")\n",
    "print(\"   - Acronym expansion and readability improvements are effective\")\n",
    "print()\n",
    "print(\"3. MODERNBERT ARCHITECTURE OUTPERFORMS STANDARD BERT\")\n",
    "print(\"   - Rotary positional embeddings and extended context help\")\n",
    "print(\"   - Consistent improvements across all medical domains\")\n",
    "print()\n",
    "print(\"4. DOMAIN-SPECIFIC PERFORMANCE VARIATIONS\")\n",
    "print(\"   - Some medical domains are better captured than others\")\n",
    "print(\"   - Structural domains (Anatomy) perform better than functional (Pharmacology)\")\n",
    "print()\n",
    "print(\"5. PRACTICAL IMPLICATIONS FOR MEDICAL EDUCATION\")\n",
    "print(\"   - Computational alignment enables automated curriculum organization\")\n",
    "print(\"   - Potential for personalized learning path generation\")\n",
    "print(\"   - Framework for evaluating educational content organization\")\n",
    "print()\n",
    "print(\"FUTURE WORK:\")\n",
    "print(\"- Extend to other medical knowledge bases (UMLS, SNOMED)\")\n",
    "print(\"- Investigate multimodal approaches (text + images)\")\n",
    "print(\"- Develop real-time curriculum alignment systems\")\n",
    "print(\"- Explore cross-institutional knowledge transfer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}